{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# #!pip install patchify\n",
        "# !pip3 install segmentation_models\n",
        "# !pip install -U -q segmentation-models\n",
        "# !pip install -q tensorflow==2.2.1\n",
        "# !pip install -q keras==2.5"
      ],
      "metadata": {
        "id": "zUqlaEQxHzl-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google  import colab\n",
        "from  google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EtbdQZkLTDe",
        "outputId": "7a88efa1-019d-4e6d-9213-cc93af882bf3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CCiaPYAwI5rZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/path/to/tensorflow/keras/metrics')\n",
        "!pip install segmentation_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONxOHxIcKH-I",
        "outputId": "3b62f724-e7c6-49a2-bd01-13c60317db2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation_models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from segmentation_models)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting image-classifiers==1.0.0 (from segmentation_models)\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting efficientnet==1.0.0 (from segmentation_models)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (24.0)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation_models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation_models-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade segmentation_models\n",
        "!pip install keras==2.6.0\n",
        "!pip install patchify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e1bYVi8AIYK",
        "outputId": "c254f20c-a91d-43dd-8fde-b7918eefc91c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation_models in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from segmentation_models) (1.0.8)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (24.0)\n",
            "Collecting keras==2.6.0\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.6.0\n",
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from patchify) (1.25.2)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWevxLOCGVKs",
        "outputId": "53767cf3-ca46-4e55-938c-9c1a534d5f29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras==2.6.0 in /usr/local/lib/python3.10/dist-packages (2.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade keras segmentation_models\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASDFyeajGdQL",
        "outputId": "09e577e5-40d7-4380-f8a9-2d8d694ac5fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.6.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: segmentation_models in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Collecting namex (from keras)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras) (0.1.8)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from segmentation_models) (1.0.8)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (24.0)\n",
            "Installing collected packages: namex, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.6.0\n",
            "    Uninstalling keras-2.6.0:\n",
            "      Successfully uninstalled keras-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.0.5 namex-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHcl21voGpc3",
        "outputId": "fd8dfd0f-06f8-44ee-d9ef-3cf9871b53e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.0.5\n",
            "    Uninstalling keras-3.0.5:\n",
            "      Successfully uninstalled keras-3.0.5\n",
            "Successfully installed keras-2.15.0\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RDyfioBKCt7",
        "outputId": "0b6200db-eeac-4b96-d8a1-054f0f8dea0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting keras\n",
            "  Using cached keras-3.0.5-py3-none-any.whl (1.0 MB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras) (0.1.8)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPEy5017Hf57",
        "outputId": "0f25b0e8-d9cf-495c-d758-228d89674c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras) (0.1.8)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: segmentation_models in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from segmentation_models) (1.0.8)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (24.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade keras\n",
        "!pip install --upgrade segmentation_models\n",
        "\n",
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from  patchify import patchify\n",
        "from PIL import Image\n",
        "#import segmentation_models as sm\n",
        "from tensorflow import keras\n",
        "from  tensorflow.keras.metrics import MeanIoU\n",
        "from sklearn.preprocessing import MinMaxScaler , StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/AerialImageryDataset')\n",
        "import simple_multi_unet_model\n",
        "from simple_multi_unet_model import multi_unet_model , jacard_coef"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "Ay5zhirzHoZW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/drive/MyDrive/AerialImageryDataset'"
      ],
      "metadata": {
        "id": "x-HRUeJxJV6V"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 256"
      ],
      "metadata": {
        "id": "7yOcn0X7L3aS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset = []\n",
        "for path , sub_dir  , files in os.walk(root_dir):\n",
        "  dirname = path.split(os.path.sep)[-1]\n",
        "  if dirname == 'images': #find files with name \"images\" or \"image\" directory\n",
        "    images = os.listdir(path) #list of all image names in this subdirectory\n",
        "    for i , image_name in enumerate(images):\n",
        "      if image_name.endswith(\".jpg\"):#read only jpeg images\n",
        "        image = cv.imread(path + '/' + image_name , 1) # 1 for reading rgb image #reading the path names\n",
        "        size_x = (image.shape[1]//patch_size)*patch_size #scaling factors of x and y\n",
        "        size_y = (image.shape[0]//patch_size)*patch_size\n",
        "        image = Image.fromarray(image)#forming array of the image\n",
        "        image = image.crop((0,0,size_x , size_y))\n",
        "\n",
        "        image = np.array(image)#forming numpy array of images\n",
        "        #extracting  patches\n",
        "        print(\"now patchifying image \" , path +\"/\" + image_name )\n",
        "        patches_img =patchify(image , (patch_size , patch_size , 3) , step = patch_size) #no overlapping\n",
        "        for i in  range(patches_img.shape[0]):\n",
        "          for j in range(patches_img.shape[1]):\n",
        "            single_patch_img = patches_img[i , j ,: , :]\n",
        "            single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)\n",
        "\n",
        "            single_patch_img = single_patch_img[0]\n",
        "            image_dataset.append(single_patch_img)\n",
        "\n"
      ],
      "metadata": {
        "id": "zgYxCKn3L6-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "622cbf49-5cf1-4b4d-dda0-442533092cd8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 6/images/image_part_009.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 6/images/image_part_005.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 6/images/image_part_001.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 6/images/image_part_002.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 6/images/image_part_004.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 6/images/image_part_006.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 6/images/image_part_007.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 6/images/image_part_003.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 6/images/image_part_008.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 5/images/image_part_007.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 5/images/image_part_009.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 5/images/image_part_002.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 5/images/image_part_005.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 5/images/image_part_008.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 5/images/image_part_004.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 5/images/image_part_003.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 5/images/image_part_001.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 5/images/image_part_006.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 3/images/image_part_005.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 3/images/image_part_003.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 3/images/image_part_009.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 3/images/image_part_008.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 3/images/image_part_004.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 3/images/image_part_002.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 3/images/image_part_001.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 3/images/image_part_006.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 3/images/image_part_007.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 7/images/image_part_005.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 7/images/image_part_001.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 7/images/image_part_003.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 7/images/image_part_008.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 7/images/image_part_007.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 7/images/image_part_006.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 7/images/image_part_009.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 7/images/image_part_004.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 7/images/image_part_002.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 4/images/image_part_008.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 4/images/image_part_004.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 4/images/image_part_005.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 4/images/image_part_003.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 4/images/image_part_009.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 4/images/image_part_002.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 4/images/image_part_007.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 4/images/image_part_001.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 4/images/image_part_006.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 8/images/image_part_003.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 8/images/image_part_007.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 8/images/image_part_006.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 8/images/image_part_008.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 8/images/image_part_004.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 8/images/image_part_002.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 8/images/image_part_001.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 8/images/image_part_005.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 8/images/image_part_009.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 1/images/image_part_009.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 1/images/image_part_001.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 1/images/image_part_005.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 1/images/image_part_003.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 1/images/image_part_006.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 1/images/image_part_008.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 1/images/image_part_004.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 1/images/image_part_007.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 1/images/image_part_002.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 2/images/image_part_002.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 2/images/image_part_003.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 2/images/image_part_008.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 2/images/image_part_009.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 2/images/image_part_006.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 2/images/image_part_001.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 2/images/image_part_005.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 2/images/image_part_004.jpg\n",
            "now patchifying image  /content/drive/MyDrive/AerialImageryDataset/Tile 2/images/image_part_007.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#doing the same with masks\n",
        "mask_dataset = []\n",
        "for path , subdirs  , files in os.walk(root_dir):\n",
        "  dirname = path.split(os.path.sep)[-1]\n",
        "  if dirname == 'masks': #find files with name \"images\" or \"image\" directory\n",
        "    masks = os.listdir(path) #list of all image names in this subdirectory\n",
        "    for i ,mask_name in enumerate(masks):\n",
        "      if mask_name.endswith(\".png\"):#read only jpeg images\n",
        "        mask = cv.imread(path + '/' + mask_name , 1) # 1 for reading rgb image #reading the path names\n",
        "        mask = cv.cvtColor(mask , cv.COLOR_BGR2RGB)\n",
        "        size_x = (mask.shape[1]//patch_size)*patch_size #scaling factors of x and y\n",
        "        size_y = (mask.shape[0]//patch_size)*patch_size\n",
        "        mask =Image.fromarray(mask)#forming array of the image\n",
        "        mask =mask.crop((0,0,size_x , size_y))\n",
        "\n",
        "        mask = np.array(mask )#forming numpy array of images\n",
        "        #extracting  patches\n",
        "        print(\"now patchifying mask \" , path +\"/\" + mask_name )\n",
        "        patches_mask =patchify(mask , (patch_size , patch_size , 3) , step = patch_size) #no overlapping\n",
        "        for i in  range(patches_mask.shape[0]):\n",
        "          for j in range(patches_mask.shape[1]):\n",
        "            single_patch_mask = patches_mask[i , j ,: , :]\n",
        "            single_patch_mask = single_patch_mask[0]\n",
        "            mask_dataset.append(single_patch_mask)\n"
      ],
      "metadata": {
        "id": "UFcyV73wSrj5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "739f2d19-92ad-49dd-91a6-23113090955e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 6/masks/image_part_004.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 6/masks/image_part_007.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 6/masks/image_part_008.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 6/masks/image_part_003.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 6/masks/image_part_006.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 6/masks/image_part_001.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 6/masks/image_part_005.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 6/masks/image_part_002.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 6/masks/image_part_009.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 5/masks/image_part_003.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 5/masks/image_part_006.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 5/masks/image_part_004.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 5/masks/image_part_008.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 5/masks/image_part_002.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 5/masks/image_part_007.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 5/masks/image_part_001.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 5/masks/image_part_005.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 5/masks/image_part_009.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_002.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_001.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_007 (1).png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_005 (1).png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_005.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_009 (1).png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_004 (1).png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_003.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_008 (1).png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_009.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_006.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_008.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_004.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 3/masks/image_part_007.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 7/masks/image_part_002.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 7/masks/image_part_004.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 7/masks/image_part_001.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 7/masks/image_part_009.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 7/masks/image_part_003.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 7/masks/image_part_006.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 7/masks/image_part_007.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 7/masks/image_part_005.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 7/masks/image_part_008.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 4/masks/image_part_003.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 4/masks/image_part_009.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 4/masks/image_part_001.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 4/masks/image_part_002.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 4/masks/image_part_005.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 4/masks/image_part_007.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 4/masks/image_part_008.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 4/masks/image_part_006.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 4/masks/image_part_004.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 8/masks/image_part_008.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 8/masks/image_part_006.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 8/masks/image_part_004.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 8/masks/image_part_001.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 8/masks/image_part_009.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 8/masks/image_part_007.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 8/masks/image_part_002.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 8/masks/image_part_003.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 8/masks/image_part_005.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 1/masks/image_part_006.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 1/masks/image_part_007.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 1/masks/image_part_008.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 1/masks/image_part_004.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 1/masks/image_part_005.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 1/masks/image_part_002.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 1/masks/image_part_009.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 1/masks/image_part_003.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 1/masks/image_part_001.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 2/masks/image_part_002.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 2/masks/image_part_008.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 2/masks/image_part_001.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 2/masks/image_part_005.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 2/masks/image_part_003.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 2/masks/image_part_007.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 2/masks/image_part_006.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 2/masks/image_part_004.png\n",
            "now patchifying mask  /content/drive/MyDrive/AerialImageryDataset/Tile 2/masks/image_part_009.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset = np.array(image_dataset)\n",
        "mask_dataset = np.array(mask_dataset)"
      ],
      "metadata": {
        "id": "Q7Ghfdg3aGJr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(len(image_dataset))"
      ],
      "metadata": {
        "id": "QimnKQ2haVRY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "# image_number = random.randint(0 , len(image_dataset))\n",
        "# plt.figure(figsize = (12,6))\n",
        "# plt.subplot(121)\n",
        "# plt.imshow(np.reshape(image_dataset[image_number],(patch_size , patch_size , 3)))\n",
        "# plt.subplot(122)\n",
        "# plt.imshow(np.reshape(mask_dataset[image_number],(patch_size , patch_size , 3)))\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "W6n3yH3ZbVjA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tackling mask : RGB TO HEX:HEX  is hexadecimal format\n",
        "# The dataset consists of aerial imagery of Dubai obtained by MBRSC satellites and annotated with pixel-wise semantic segmentation in 6 classes. The total volume of the dataset is 72 images grouped into 6 larger tiles. The classes are:\n",
        "\n",
        "# Building: #3C1098\n",
        "# Land (unpaved area): #8429F6\n",
        "# Road: #6EC1E4\n",
        "# Vegetation: #FEDD3A\n",
        "# Water: #E2A929\n",
        "# Unlabeled: #9B9B9B\n",
        "\n",
        "# Calculating RGB from HEX: #3C1098\n",
        "# 3C = 3*16 + 12 = 60\n",
        "# 10 = 1*16 + 0 = 16\n",
        "# 98 = 9*16 + 8 = 152\n",
        "\n",
        "#converting  each class's hex code to RGN\n",
        "\n",
        "Building = '#3C1098'.lstrip('#')\n",
        "Building  = np.array(tuple(int(Building[i:i+2],16)for i in  (0,2,4)))\n",
        "\n",
        "Land = '#8429F6'.lstrip('#')\n",
        "Land  = np.array(tuple(int(Land[i:i+2],16)for i in  (0,2,4)))\n",
        "\n",
        "Road = '#6EC1E4'.lstrip('#')\n",
        "Road  = np.array(tuple(int(Road[i:i+2],16)for i in  (0,2,4)))\n",
        "\n",
        "Vegetation = '#FEDD3A'.lstrip('#')\n",
        "Vegetation  = np.array(tuple(int(Vegetation[i:i+2],16)for i in  (0,2,4)))\n",
        "\n",
        "Water = '#E2A929'.lstrip('#')\n",
        "Water  = np.array(tuple(int(Water[i:i+2],16)for i in  (0,2,4)))\n",
        "\n",
        "Unlabeled = '#9B9B9B'.lstrip('#')\n",
        "Unlabeled  = np.array(tuple(int(Unlabeled[i:i+2],16)for i in  (0,2,4)))\n",
        "\n",
        "label = single_patch_mask"
      ],
      "metadata": {
        "id": "IiobEx0KblhR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Building)"
      ],
      "metadata": {
        "id": "grejqjhdjcFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2177ba28-079b-4e14-9310-34dab769b819"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 60  16 152]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing rgb to intefer then to one hot encoded\n",
        "#for this replacing rgb to integers values to be used as labels , find pixels with combination of RGB for above defined arrays , if matched then replace all values in that pixels with a specific integer\n",
        "def rgb_2_2Dlabels(label):\n",
        "  label_seg = np.zeros(label.shape , dtype = np.uint8)\n",
        "  label_seg[np.all(label == Building , axis = -1)] = 0\n",
        "  label_seg[np.all(label ==Land , axis = -1)] = 1\n",
        "  label_seg[np.all(label == Road , axis = -1)] = 2\n",
        "  label_seg[np.all(label == Vegetation , axis = -1)] = 3\n",
        "  label_seg[np.all(label == Water , axis = -1)] = 4\n",
        "  label_seg[np.all(label == Unlabeled , axis = -1)] = 5\n",
        "\n",
        "  label_seg = label_seg[:,:,0]\n",
        "  return label_seg\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bf0gcuNCkaRI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "for i in range(mask_dataset.shape[0]):\n",
        "  label = rgb_2_2Dlabels(mask_dataset[i])\n",
        "  labels.append(label)\n"
      ],
      "metadata": {
        "id": "h7Sp0XPb0vCK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array(labels)\n",
        "labels = np.expand_dims(labels , axis = 3)"
      ],
      "metadata": {
        "id": "yD8BSwbY1FJT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"unique labels : \" , np.unique(labels))\n"
      ],
      "metadata": {
        "id": "reL0HUuN1RbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926a27b3-9751-44bc-e0dd-1f86a8d99c17"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique labels :  [0 1 2 3 4 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "# image_number = random.randint(0 , len(image_dataset))\n",
        "# plt.figure(figsize = (12,6))\n",
        "# plt.subplot(121)\n",
        "# plt.imshow(image_dataset[image_number])\n",
        "# plt.subplot(122)\n",
        "# plt.imshow(labels[image_number][:,:,0])\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "M4eZjPk61aHF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding\n",
        "n_classes = len(np.unique(labels))\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "labels_cat = to_categorical(labels , num_classes = n_classes)"
      ],
      "metadata": {
        "id": "ksu-hLdB1nLs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels_cat.shape)"
      ],
      "metadata": {
        "id": "iXqMOVUq21K0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff06a706-bae9-4bfd-e8a7-4f7455b660d0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1325, 256, 256, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Check the number of samples in each dataset\n",
        "num_samples_image = len(image_dataset)\n",
        "num_samples_labels = len(labels_cat)\n",
        "\n",
        "# Ensure both datasets have the same number of samples\n",
        "if num_samples_image != num_samples_labels:\n",
        "    min_samples = min(num_samples_image, num_samples_labels)\n",
        "    image_dataset = image_dataset[:min_samples]\n",
        "    labels_cat = labels_cat[:min_samples]\n",
        "    print(\"Number of samples adjusted to:\", min_samples)\n",
        "\n",
        "# Split the datasets into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(image_dataset, labels_cat, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "OBK2t_OS4CFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34aed1aa-cbea-488a-c558-fc668b00b0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples adjusted to: 1305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "8twk6pId6O3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = [0.1666,0.1666,0.1666,0.1666,0.1666,0.1666]\n",
        "dice_loss = sm.losses.DiceLoss(class_weights = weights)\n",
        "focal_loss = sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1*focal_loss)\n",
        "\n",
        "img_height = x_train.shape[1]\n",
        "img_width = x_train.shape[2]\n",
        "img_channels = x_train.shape[3]\n"
      ],
      "metadata": {
        "id": "k1szvIrR2sgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "metrics = ['accuracy',jacard_coef]\n",
        "def get_model():\n",
        "  return multi_unet_model(n_classes = n_classes , IMG_HEIGHT = img_height , IMG_WIDTH = img_width , IMG_CHANNELS = img_channels)\n",
        "\n"
      ],
      "metadata": {
        "id": "T6sYKZih6n8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.compile(loss = total_loss , optimizer = 'adam' , metrics = metrics)\n",
        "model.summary"
      ],
      "metadata": {
        "id": "7xu0Dtsw9C-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitting = model.fit(x_train , y_train , batch_size = 16, verbose = 1 , epochs  = 10 , validation_data = (x_test , y_test ) , shuffle = False)"
      ],
      "metadata": {
        "id": "-zg9yEPk9jB7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}